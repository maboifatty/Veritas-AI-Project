{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13383542,"sourceType":"datasetVersion","datasetId":8491828}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport warnings\nimport pickle\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndf = pd.read_csv('/kaggle/input/satellite-orbital-data/train_data.csv')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:13:48.676020Z","iopub.execute_input":"2025-12-18T05:13:48.676361Z","iopub.status.idle":"2025-12-18T05:13:52.416329Z","shell.execute_reply.started":"2025-12-18T05:13:48.676336Z","shell.execute_reply":"2025-12-18T05:13:52.415411Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/satellite-orbital-data/train_data 2.csv\n/kaggle/input/satellite-orbital-data/train_data.csv\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"categorical_columns = []\nfor column in df.columns:\n    df[column] = (pd.to_numeric(df[column], errors=\"coerce\")).fillna(0)\n    if (df[column].max() == df[column].min()==0):\n        categorical_columns.append(column)\n\n    if(df[column].max()>1e10):\n        indices = np.where(df[column]>1e10)[0]\n        df.loc[indices, column] = 1e10\n\n\n\nprint (categorical_columns)\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:08:48.373686Z","iopub.execute_input":"2025-12-18T05:08:48.374347Z","iopub.status.idle":"2025-12-18T05:08:48.760346Z","shell.execute_reply.started":"2025-12-18T05:08:48.374301Z","shell.execute_reply":"2025-12-18T05:08:48.759596Z"}},"outputs":[{"name":"stdout","text":"['c_object_type']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def SF_create_random_forest(column, num_estimators):\n    X_single = np.array(df[column].fillna(0)).reshape(-1,1)\n    y = np.array(df['risk'])\n    bins = [-np.inf, -15, -5, 5, np.inf]\n    labels = ['high', 'medium', 'low', 'very_low'] \n    \n    y = pd.cut(y, bins=bins, labels=labels) #allows splitting of continuous values into variables based on provided bins \n\n    # Train/test split\n    X_train, X_test, y_train, y_test = train_test_split(\n    X_single, y, test_size=0.2, random_state=7\n    )\n\n    # Random Forest\n    model = RandomForestClassifier(n_estimators = num_estimators, random_state=7)\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n\n    print (\"Risk is estimated to be\", y_pred, \"based on\", column)\n    print(f\"Accuracy for miss: {accuracy:.2f}\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:07:21.742193Z","iopub.execute_input":"2025-12-07T18:07:21.742998Z","iopub.status.idle":"2025-12-07T18:07:21.748254Z","shell.execute_reply.started":"2025-12-07T18:07:21.742963Z","shell.execute_reply":"2025-12-07T18:07:21.747524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_copy = df.copy()\nfor column in df.columns:\n    df_copy[column]=df.loc[0, column]\n    df_copy[column+'_1']=df.loc[1, column]\n    df_copy[column+'_2']=df.loc[2, column]\n    df_copy[column+'_3']=df.loc[3, column]\n    df_copy[column+'_4']=df.loc[4, column]\n\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:23:01.618516Z","iopub.execute_input":"2025-12-07T22:23:01.619368Z","iopub.status.idle":"2025-12-07T22:23:01.916157Z","shell.execute_reply.started":"2025-12-07T22:23:01.619339Z","shell.execute_reply":"2025-12-07T22:23:01.915092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_copy = df.copy()\nunique_id = np.unique(df['event_id'])\nfor e_id in unique_id:\n    indices = np.where(df['event_id']==e_id)\n    indices = indices[0]\n    for column in df.columns:\n        df_copy[column]=df.loc[indices[0],column]\n        for index in indices[1:]:\n            df_copy[column+f'_{index}']=df.loc[index,column]\n        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:23:05.968196Z","iopub.execute_input":"2025-12-07T22:23:05.968593Z","iopub.status.idle":"2025-12-07T22:24:48.204211Z","shell.execute_reply.started":"2025-12-07T22:23:05.968568Z","shell.execute_reply":"2025-12-07T22:24:48.202892Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_copy = df.copy()\nunique_id = np.unique(df['event_id'])\nfirst_indices = []\nall_indices = [[] for i in range(20)] #20 as placeholder for max num of estimates\nfor e_id in unique_id:\n    indices = np.where(df['event_id']==e_id)\n    indices = indices[0]\n    first_indices.append(indices[0])\n    for index in indices:\n        all_indices.append()\nfor column in df.columns:\n    df_copy[column]=df.loc(first_indices,column)\n    for index in indices[1:]:\n        \n\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:08:11.582748Z","iopub.execute_input":"2025-12-07T22:08:11.583850Z","iopub.status.idle":"2025-12-07T22:08:11.735072Z","shell.execute_reply.started":"2025-12-07T22:08:11.583816Z","shell.execute_reply":"2025-12-07T22:08:11.733825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nlagged_features=[]\ndf_copy= df.copy()\nunique_id= np.unique(df['event_id'])\nfor e_id in unique_id:\n    indices = np.where(df['event_id']==e_id)[0]\n    for i in range(1,len(indices)):\n        index = indices[i]\n        for column in df.columns:\n            df_copy[column+str(i)]=np.array(df[column])[index]\n        print (df_copy.head(1))\n        df_copy.drop(index=i)\n    \n    break\nprint(df_copy.shape[0]*df_copy.shape[1])\nprint(df.shape[0]*df.shape[1])\nprint(\"df\", df.shape)\nprint(\"copy\", df_copy.shape)\n            \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:37:14.351822Z","iopub.execute_input":"2025-12-07T23:37:14.352157Z","iopub.status.idle":"2025-12-07T23:37:14.747489Z","shell.execute_reply.started":"2025-12-07T23:37:14.352135Z","shell.execute_reply":"2025-12-07T23:37:14.746721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndf_copy= df.copy()\nunique_id= np.unique(df['event_id'])\nfor e_id in unique_id:\n    lagged_features=[]\n    indices = np.where(df['event_id']==e_id)[0]\n    for i in range(1,len(indices)):\n        index = indices[i]\n        for column in df.columns:\n            df_copy[column+str(i)]=np.array(df[column])[index]\n            df_copy[f'{column}_lag{i}'] = df_copy.groupby('event_id')[column].shift(i)\n            lagged_features.append(df_copy.groupby('event_id')[column].shift(i).rename(f'{column}_lag{i}'))\n        print (df_copy.head(1))\n        df_copy.drop(index=i)\n    df_copy = pd.concat([df_copy] + lagged_features, axis=1)\ndf_copy = df_copy.groupby('event_id').last().reset_index()\nprint(df_copy.shape[0]*df_copy.shape[1])\nprint(df.shape[0]*df.shape[1])\nprint(\"df\", df.shape)\nprint(\"copy\", df_copy.shape)\n            \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:51:38.970172Z","iopub.execute_input":"2025-12-07T23:51:38.970497Z","execution_failed":"2025-12-07T23:57:03.412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eids = np.unique(df[\"event_id\"])\nmax_len_eid = 0\nfor eid in eids:\n  inds = np.where(df[\"event_id\"] == eid)[0]\n  max_len_eid = max(max_len_eid, len(str(len(inds))))\n\nprint(max_len_eid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:08:55.926290Z","iopub.execute_input":"2025-12-18T05:08:55.926974Z","iopub.status.idle":"2025-12-18T05:08:58.713719Z","shell.execute_reply.started":"2025-12-18T05:08:55.926927Z","shell.execute_reply":"2025-12-18T05:08:58.712950Z"}},"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"max_len_column = 0\nfor column in df.columns:\n  max_len_column = max(max_len_column, len(column))\n\nprint(max_len_column)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:10:50.006291Z","iopub.execute_input":"2025-12-18T05:10:50.006668Z","iopub.status.idle":"2025-12-18T05:10:50.012392Z","shell.execute_reply.started":"2025-12-18T05:10:50.006641Z","shell.execute_reply":"2025-12-18T05:10:50.011374Z"}},"outputs":[{"name":"stdout","text":"25\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def time_series_cleaning():\n    new_df = None\n    for eid in eids:\n        inds = np.where(df[\"event_id\"] == eid)[0]\n        columns = np.zeros(len(inds)*len(df.columns), dtype=f\"U{max_len_column+max_len_eid}\")\n        values  = np.zeros(len(inds)*len(df.columns))\n    \n    cnt = -1\n    for i, ind in enumerate(inds):\n      for j, column in enumerate(df.columns):\n        cnt += 1\n        columns[cnt] = str(column)+str(i)\n        try:\n          values[cnt] = df.iloc[ind][column]\n        except:\n          values[cnt] = np.nan # handle non-numeric types\n    \n    if new_df is None:\n      new_df = pd.DataFrame(data=values.reshape(1, -1), columns=columns)\n    else:\n      new_df = pd.concat([new_df, pd.DataFrame(data=values.reshape(1, -1), columns=columns)])\n\n    with open(\"/kaggle/working/train_data.pkl\", \"wb\") as f:\n        pickle.dump(new_df, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:16:32.989970Z","iopub.execute_input":"2025-12-18T05:16:32.990635Z","iopub.status.idle":"2025-12-18T05:16:32.998517Z","shell.execute_reply.started":"2025-12-18T05:16:32.990603Z","shell.execute_reply":"2025-12-18T05:16:32.997279Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"time_series_cleaning()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:16:41.921290Z","iopub.execute_input":"2025-12-18T05:16:41.921647Z","iopub.status.idle":"2025-12-18T05:16:44.877769Z","shell.execute_reply.started":"2025-12-18T05:16:41.921621Z","shell.execute_reply":"2025-12-18T05:16:44.876830Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"max_len_column = 0\nfor column in df.columns:\n  max_len_column = max(max_len_column, len(column))\n\nprint(max_len_column)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#10 tree forest\naccuracy_of_estimates10sf = []\nfor column in df.columns:\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates10sf.append(SF_create_random_forest(column, 10))\n\nprint (accuracy_of_estimates10sf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:39:52.241041Z","iopub.execute_input":"2025-12-07T18:39:52.241327Z","iopub.status.idle":"2025-12-07T18:44:21.582504Z","shell.execute_reply.started":"2025-12-07T18:39:52.241290Z","shell.execute_reply":"2025-12-07T18:44:21.581753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'10 Trees':accuracy_of_estimates10sf}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('10TreeSingleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:40:41.927732Z","iopub.execute_input":"2025-11-30T18:40:41.927962Z","iopub.status.idle":"2025-11-30T18:40:41.933820Z","shell.execute_reply.started":"2025-11-30T18:40:41.927949Z","shell.execute_reply":"2025-11-30T18:40:41.932726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barcharts\n\naccuracies = accuracy_of_estimates10sf \nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(df.columns)[indices]\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:45:14.614981Z","iopub.execute_input":"2025-12-07T18:45:14.615470Z","iopub.status.idle":"2025-12-07T18:45:14.759159Z","shell.execute_reply.started":"2025-12-07T18:45:14.615449Z","shell.execute_reply":"2025-12-07T18:45:14.758243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#30 trees\naccuracy_of_estimates30sf = []\nfor column in df.columns:\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates30sf.append(SF_create_random_forest(column, 30))\n\nprint (accuracy_of_estimates30sf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:45:56.621200Z","iopub.execute_input":"2025-12-07T18:45:56.621913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'30 Trees':accuracy_of_estimates30sf}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('30TreeSingleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T01:37:41.937611Z","iopub.status.idle":"2025-12-01T01:37:41.937834Z","shell.execute_reply.started":"2025-12-01T01:37:41.937718Z","shell.execute_reply":"2025-12-01T01:37:41.937729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barcharts\n\naccuracies = accuracy_of_estimates30sf\nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(df.columns)[indices]\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:28:33.692961Z","iopub.execute_input":"2025-12-07T18:28:33.693191Z","iopub.status.idle":"2025-12-07T18:28:33.829839Z","shell.execute_reply.started":"2025-12-07T18:28:33.693176Z","shell.execute_reply":"2025-12-07T18:28:33.829135Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#100 trees\naccuracy_of_estimates = []\nfor column in df.columns:\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates.append(SF_create_random_forest(column, 100))\n\nprint (accuracy_of_estimates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T19:02:26.641787Z","iopub.execute_input":"2025-11-30T19:02:26.642088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'100 Trees':accuracy_of_estimates}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('100TreeSingleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:25:11.022710Z","iopub.status.idle":"2025-11-30T18:25:11.023104Z","shell.execute_reply.started":"2025-11-30T18:25:11.022963Z","shell.execute_reply":"2025-11-30T18:25:11.022975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barcharts\n\naccuracies = accuracy_of_estimates \nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(df.columns)[indices]\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:25:11.024789Z","iopub.status.idle":"2025-11-30T18:25:11.025139Z","shell.execute_reply.started":"2025-11-30T18:25:11.025023Z","shell.execute_reply":"2025-11-30T18:25:11.025033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def DF_create_random_forest(column1, column2, num_estimators):\n    features = [column1, column2]\n    X = ((df[features].to_numpy()))#.reshape(-1,1)\n    y = np.array(df['risk'])\n    bins = [-np.inf, -15, -5, 5, np.inf]\n    labels = ['high', 'medium', 'low', 'very_low'] \n    \n    y = pd.cut(y, bins=bins, labels=labels) #allows splitting of continuous values into variables based on provided bins \n\n    # Train/test split\n    X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=7\n    )\n\n    # Random Forest\n    model = RandomForestClassifier(n_estimators=num_estimators, random_state=7)\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n\n    print (\"Risk is estimated to be\", y_pred, \"based on\", column1, \"and\", column2)\n    print(f\"Accuracy for miss: {accuracy:.2f}\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:29:57.722980Z","iopub.execute_input":"2025-12-07T18:29:57.723847Z","iopub.status.idle":"2025-12-07T18:29:57.730983Z","shell.execute_reply.started":"2025-12-07T18:29:57.723814Z","shell.execute_reply":"2025-12-07T18:29:57.730062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#10 trees\naccuracy_of_estimates10df = []\ndual_column_list=[]\nfor i in range(0,len(df.columns)-1,2):\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates10df.append(DF_create_random_forest(df.columns[i], df.columns[i+1], 10))\n    dual_column_list.append([df.columns[i],df.columns[i+1]])\n\nprint (accuracy_of_estimates10df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:30:32.252639Z","iopub.execute_input":"2025-12-07T18:30:32.252894Z","iopub.status.idle":"2025-12-07T18:32:27.362601Z","shell.execute_reply.started":"2025-12-07T18:30:32.252881Z","shell.execute_reply":"2025-12-07T18:32:27.361827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'10 Trees':accuracy_of_estimates10df}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('10TreeDoubleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T01:53:06.700645Z","iopub.execute_input":"2025-12-01T01:53:06.701206Z","iopub.status.idle":"2025-12-01T01:53:06.707376Z","shell.execute_reply.started":"2025-12-01T01:53:06.701177Z","shell.execute_reply":"2025-12-01T01:53:06.705859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barchartsdf\n\naccuracies = accuracy_of_estimates10df\nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(dual_column_list)[indices]\ncolumns = [\" & \".join(col) if isinstance(col, (list, np.ndarray)) else str(col) \n           for col in columns]\nprint (columns)\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:33:21.062387Z","iopub.execute_input":"2025-12-07T18:33:21.062752Z","iopub.status.idle":"2025-12-07T18:33:21.210902Z","shell.execute_reply.started":"2025-12-07T18:33:21.062729Z","shell.execute_reply":"2025-12-07T18:33:21.210101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#30 trees\naccuracy_of_estimates30df = []\ndual_column_list=[]\nfor i in range(0,len(df.columns)-1,2):\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates30df.append(DF_create_random_forest(df.columns[i], df.columns[i+1], 30))\n    dual_column_list.append([df.columns[i],df.columns[i+1]])\n\nprint (accuracy_of_estimates30df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:31:18.754567Z","iopub.execute_input":"2025-12-01T03:31:18.754849Z","iopub.status.idle":"2025-12-01T03:38:34.406085Z","shell.execute_reply.started":"2025-12-01T03:31:18.754831Z","shell.execute_reply":"2025-12-01T03:38:34.405267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'30 Trees':accuracy_of_estimates30df}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('30TreeDoubleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:24:15.490848Z","iopub.execute_input":"2025-12-01T02:24:15.492165Z","iopub.status.idle":"2025-12-01T02:24:15.497591Z","shell.execute_reply.started":"2025-12-01T02:24:15.492120Z","shell.execute_reply":"2025-12-01T02:24:15.496805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barchartsdf\n\naccuracies = accuracy_of_estimates30df\nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(dual_column_list)[indices]\ncolumns = [\" & \".join(col) if isinstance(col, (list, np.ndarray)) else str(col) \n           for col in columns]\nprint (columns)\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#100 trees\naccuracy_of_estimatesdf = []\ndual_column_list=[]\nfor i in range(0,len(df.columns)-1,2):\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimatesdf.append(DF_create_random_forest(df.columns[i], df.columns[i+1], 100))\n    dual_column_list.append([df.columns[i],df.columns[i+1]])\n\nprint (accuracy_of_estimatesdf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:24:46.377746Z","iopub.execute_input":"2025-12-01T02:24:46.378075Z","iopub.status.idle":"2025-12-01T02:49:53.477624Z","shell.execute_reply.started":"2025-12-01T02:24:46.378057Z","shell.execute_reply":"2025-12-01T02:49:53.476738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'100 Trees':accuracy_of_estimatesdf}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('100TreeDoubleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:26:47.196008Z","iopub.execute_input":"2025-12-01T03:26:47.196580Z","iopub.status.idle":"2025-12-01T03:26:47.203713Z","shell.execute_reply.started":"2025-12-01T03:26:47.196558Z","shell.execute_reply":"2025-12-01T03:26:47.202172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barchartsdf\n\naccuracies = accuracy_of_estimatesdf\nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(dual_column_list)[indices]\ncolumns = [\" & \".join(col) if isinstance(col, (list, np.ndarray)) else str(col) \n           for col in columns]\nprint (columns)\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:41:09.022826Z","iopub.execute_input":"2025-12-01T03:41:09.023142Z","iopub.status.idle":"2025-12-01T03:41:09.213877Z","shell.execute_reply.started":"2025-12-01T03:41:09.023127Z","shell.execute_reply":"2025-12-01T03:41:09.211997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#normalization\nx = df[\"miss_distance\"]\nxmin = x.min()\nx-=xmin\nxmax = x.max()\nx/=xmax\nprint (x, x.min(), x.max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:35:09.920503Z","iopub.execute_input":"2025-12-02T00:35:09.920879Z","iopub.status.idle":"2025-12-02T00:35:09.936047Z","shell.execute_reply.started":"2025-12-02T00:35:09.920851Z","shell.execute_reply":"2025-12-02T00:35:09.934725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#normalization\nx = df[\"miss_distance\"]\nxmin = x.min()\nx-=xmin\nindices = np.where(x==x.min())[0]\nindices2 = np.where(x!=x.min())[0]\nx2 = x[indices2]\nx[indices] = x2.min()\nx = np.log10(x)\nx-=x.min()\nxmax = x.max()\nx/=xmax\nprint (x, x.min(), x.max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:36:00.207210Z","iopub.execute_input":"2025-12-02T00:36:00.207598Z","iopub.status.idle":"2025-12-02T00:36:00.250548Z","shell.execute_reply.started":"2025-12-02T00:36:00.207563Z","shell.execute_reply":"2025-12-02T00:36:00.249581Z"}},"outputs":[],"execution_count":null}]}