{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13383542,"sourceType":"datasetVersion","datasetId":8491828}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/prayagbarath/veritas-ai-random-forest-satellite-orbit-collision?scriptVersionId=290473492\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport warnings\nimport pickle\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndf = pd.read_csv('/kaggle/input/satellite-orbital-data/train_data.csv')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:10:22.690648Z","iopub.execute_input":"2025-12-19T00:10:22.690969Z","iopub.status.idle":"2025-12-19T00:10:31.494115Z","shell.execute_reply.started":"2025-12-19T00:10:22.690929Z","shell.execute_reply":"2025-12-19T00:10:31.493245Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/satellite-orbital-data/train_data 2.csv\n/kaggle/input/satellite-orbital-data/train_data.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"categorical_columns = []\nfor column in df.columns:\n    df[column] = (pd.to_numeric(df[column], errors=\"coerce\")).fillna(0)\n    if (df[column].max() == df[column].min()==0):\n        categorical_columns.append(column)\n\n    if(df[column].max()>1e10):\n        indices = np.where(df[column]>1e10)[0]\n        df.loc[indices, column] = 1e10\n\n\n\nprint (categorical_columns)\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:10:44.44095Z","iopub.execute_input":"2025-12-19T00:10:44.441261Z","iopub.status.idle":"2025-12-19T00:10:44.848878Z","shell.execute_reply.started":"2025-12-19T00:10:44.441235Z","shell.execute_reply":"2025-12-19T00:10:44.847957Z"}},"outputs":[{"name":"stdout","text":"['c_object_type']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def SF_create_random_forest(column, num_estimators):\n    X_single = np.array(df[column].fillna(0)).reshape(-1,1)\n    y = np.array(df['risk'])\n    bins = [-np.inf, -15, -5, 5, np.inf]\n    labels = ['high', 'medium', 'low', 'very_low'] \n    \n    y = pd.cut(y, bins=bins, labels=labels) #allows splitting of continuous values into variables based on provided bins \n\n    # Train/test split\n    X_train, X_test, y_train, y_test = train_test_split(\n    X_single, y, test_size=0.2, random_state=7\n    )\n\n    # Random Forest\n    model = RandomForestClassifier(n_estimators = num_estimators, random_state=7)\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n\n    print (\"Risk is estimated to be\", y_pred, \"based on\", column)\n    print(f\"Accuracy for miss: {accuracy:.2f}\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:07:21.742193Z","iopub.execute_input":"2025-12-07T18:07:21.742998Z","iopub.status.idle":"2025-12-07T18:07:21.748254Z","shell.execute_reply.started":"2025-12-07T18:07:21.742963Z","shell.execute_reply":"2025-12-07T18:07:21.747524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#time series step 1\neids = np.unique(df[\"event_id\"])\nmax_len_eid = 0\nfor eid in eids:\n  inds = np.where(df[\"event_id\"] == eid)[0] #which rows correspond to each event id; [0] to ensure 1D array\n  max_len_eid = max(max_len_eid, len(str(len(inds)))) #len(str(len)) --> how many digits is the max num of times in an eid\n\nprint(max_len_eid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:11:07.820138Z","iopub.execute_input":"2025-12-19T00:11:07.820479Z","iopub.status.idle":"2025-12-19T00:11:10.718649Z","shell.execute_reply.started":"2025-12-19T00:11:07.820452Z","shell.execute_reply":"2025-12-19T00:11:10.717717Z"}},"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#time series step 2\nmax_len_column = 0\nfor column in df.columns:\n  max_len_column = max(max_len_column, len(column)) #num symbols per column\n\nprint(max_len_column)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:11:12.659136Z","iopub.execute_input":"2025-12-19T00:11:12.659455Z","iopub.status.idle":"2025-12-19T00:11:12.665287Z","shell.execute_reply.started":"2025-12-19T00:11:12.659432Z","shell.execute_reply":"2025-12-19T00:11:12.664306Z"}},"outputs":[{"name":"stdout","text":"25\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#time series step 3: fxn\ndef time_series_cleaning():\n    new_df = None\n    for eid in eids:\n        inds = np.where(df[\"event_id\"] == eid)[0]\n        columns = np.zeros(len(inds)*len(df.columns), dtype=f\"U{max_len_column+max_len_eid}\") #dtype (datatype) U means Unicode for String: Creates a String that can store x many values\n        values  = np.zeros(len(inds)*len(df.columns))\n    \n        cnt = -1\n        for i, ind in enumerate(inds): #enumerate --> pass a list and it provides index and value\n          for j, column in enumerate(df.columns):\n            cnt += 1\n            columns[cnt] = str(column)+str(i)\n            try: #attempt the code inside,  but if error encountered defer to except block\n              values[cnt] = df.iloc[ind][column] #look at a row specified by ind and grab the value stored for the \"column\" at that row\n            except:\n              values[cnt] = np.nan # handle non-numeric types\n        \n        if new_df is None:\n          new_df = pd.DataFrame(data=values.reshape(1, -1), columns=columns)\n        else:\n          new_df = pd.concat([new_df, pd.DataFrame(data=values.reshape(1, -1), columns=columns)]) #concatenates each unique id iteration together\n\n    with open(\"/kaggle/working/train_data.pkl\", \"wb\") as f:\n        pickle.dump(new_df, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:11:46.855555Z","iopub.execute_input":"2025-12-19T00:11:46.856347Z","iopub.status.idle":"2025-12-19T00:11:46.863763Z","shell.execute_reply.started":"2025-12-19T00:11:46.856311Z","shell.execute_reply":"2025-12-19T00:11:46.862737Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"time_series_cleaning()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:11:50.042307Z","iopub.execute_input":"2025-12-19T00:11:50.04273Z","iopub.status.idle":"2025-12-19T01:00:33.210838Z","shell.execute_reply.started":"2025-12-19T00:11:50.042701Z","shell.execute_reply":"2025-12-19T01:00:33.209766Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"max_len_column = 0\nfor column in df.columns:\n  max_len_column = max(max_len_column, len(column))\n\nprint(max_len_column)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#10 tree forest\naccuracy_of_estimates10sf = []\nfor column in df.columns:\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates10sf.append(SF_create_random_forest(column, 10))\n\nprint (accuracy_of_estimates10sf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:39:52.241041Z","iopub.execute_input":"2025-12-07T18:39:52.241327Z","iopub.status.idle":"2025-12-07T18:44:21.582504Z","shell.execute_reply.started":"2025-12-07T18:39:52.24129Z","shell.execute_reply":"2025-12-07T18:44:21.581753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'10 Trees':accuracy_of_estimates10sf}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('10TreeSingleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:40:41.927732Z","iopub.execute_input":"2025-11-30T18:40:41.927962Z","iopub.status.idle":"2025-11-30T18:40:41.93382Z","shell.execute_reply.started":"2025-11-30T18:40:41.927949Z","shell.execute_reply":"2025-11-30T18:40:41.932726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barcharts\n\naccuracies = accuracy_of_estimates10sf \nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(df.columns)[indices]\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:45:14.614981Z","iopub.execute_input":"2025-12-07T18:45:14.61547Z","iopub.status.idle":"2025-12-07T18:45:14.759159Z","shell.execute_reply.started":"2025-12-07T18:45:14.615449Z","shell.execute_reply":"2025-12-07T18:45:14.758243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#30 trees\naccuracy_of_estimates30sf = []\nfor column in df.columns:\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates30sf.append(SF_create_random_forest(column, 30))\n\nprint (accuracy_of_estimates30sf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:45:56.6212Z","iopub.execute_input":"2025-12-07T18:45:56.621913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'30 Trees':accuracy_of_estimates30sf}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('30TreeSingleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T01:37:41.937611Z","iopub.status.idle":"2025-12-01T01:37:41.937834Z","shell.execute_reply.started":"2025-12-01T01:37:41.937718Z","shell.execute_reply":"2025-12-01T01:37:41.937729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barcharts\n\naccuracies = accuracy_of_estimates30sf\nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(df.columns)[indices]\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:28:33.692961Z","iopub.execute_input":"2025-12-07T18:28:33.693191Z","iopub.status.idle":"2025-12-07T18:28:33.829839Z","shell.execute_reply.started":"2025-12-07T18:28:33.693176Z","shell.execute_reply":"2025-12-07T18:28:33.829135Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#100 trees\naccuracy_of_estimates = []\nfor column in df.columns:\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates.append(SF_create_random_forest(column, 100))\n\nprint (accuracy_of_estimates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T19:02:26.641787Z","iopub.execute_input":"2025-11-30T19:02:26.642088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'100 Trees':accuracy_of_estimates}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('100TreeSingleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:25:11.02271Z","iopub.status.idle":"2025-11-30T18:25:11.023104Z","shell.execute_reply.started":"2025-11-30T18:25:11.022963Z","shell.execute_reply":"2025-11-30T18:25:11.022975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barcharts\n\naccuracies = accuracy_of_estimates \nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(df.columns)[indices]\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:25:11.024789Z","iopub.status.idle":"2025-11-30T18:25:11.025139Z","shell.execute_reply.started":"2025-11-30T18:25:11.025023Z","shell.execute_reply":"2025-11-30T18:25:11.025033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def DF_create_random_forest(column1, column2, num_estimators):\n    features = [column1, column2]\n    X = ((df[features].to_numpy()))#.reshape(-1,1)\n    y = np.array(df['risk'])\n    bins = [-np.inf, -15, -5, 5, np.inf]\n    labels = ['high', 'medium', 'low', 'very_low'] \n    \n    y = pd.cut(y, bins=bins, labels=labels) #allows splitting of continuous values into variables based on provided bins \n\n    # Train/test split\n    X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=7\n    )\n\n    # Random Forest\n    model = RandomForestClassifier(n_estimators=num_estimators, random_state=7)\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n\n    print (\"Risk is estimated to be\", y_pred, \"based on\", column1, \"and\", column2)\n    print(f\"Accuracy for miss: {accuracy:.2f}\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:29:57.72298Z","iopub.execute_input":"2025-12-07T18:29:57.723847Z","iopub.status.idle":"2025-12-07T18:29:57.730983Z","shell.execute_reply.started":"2025-12-07T18:29:57.723814Z","shell.execute_reply":"2025-12-07T18:29:57.730062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#10 trees\naccuracy_of_estimates10df = []\ndual_column_list=[]\nfor i in range(0,len(df.columns)-1,2):\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates10df.append(DF_create_random_forest(df.columns[i], df.columns[i+1], 10))\n    dual_column_list.append([df.columns[i],df.columns[i+1]])\n\nprint (accuracy_of_estimates10df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:30:32.252639Z","iopub.execute_input":"2025-12-07T18:30:32.252894Z","iopub.status.idle":"2025-12-07T18:32:27.362601Z","shell.execute_reply.started":"2025-12-07T18:30:32.252881Z","shell.execute_reply":"2025-12-07T18:32:27.361827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'10 Trees':accuracy_of_estimates10df}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('10TreeDoubleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T01:53:06.700645Z","iopub.execute_input":"2025-12-01T01:53:06.701206Z","iopub.status.idle":"2025-12-01T01:53:06.707376Z","shell.execute_reply.started":"2025-12-01T01:53:06.701177Z","shell.execute_reply":"2025-12-01T01:53:06.705859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barchartsdf\n\naccuracies = accuracy_of_estimates10df\nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(dual_column_list)[indices]\ncolumns = [\" & \".join(col) if isinstance(col, (list, np.ndarray)) else str(col) \n           for col in columns]\nprint (columns)\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:33:21.062387Z","iopub.execute_input":"2025-12-07T18:33:21.062752Z","iopub.status.idle":"2025-12-07T18:33:21.210902Z","shell.execute_reply.started":"2025-12-07T18:33:21.062729Z","shell.execute_reply":"2025-12-07T18:33:21.210101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#30 trees\naccuracy_of_estimates30df = []\ndual_column_list=[]\nfor i in range(0,len(df.columns)-1,2):\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimates30df.append(DF_create_random_forest(df.columns[i], df.columns[i+1], 30))\n    dual_column_list.append([df.columns[i],df.columns[i+1]])\n\nprint (accuracy_of_estimates30df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:31:18.754567Z","iopub.execute_input":"2025-12-01T03:31:18.754849Z","iopub.status.idle":"2025-12-01T03:38:34.406085Z","shell.execute_reply.started":"2025-12-01T03:31:18.754831Z","shell.execute_reply":"2025-12-01T03:38:34.405267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'30 Trees':accuracy_of_estimates30df}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('30TreeDoubleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:24:15.490848Z","iopub.execute_input":"2025-12-01T02:24:15.492165Z","iopub.status.idle":"2025-12-01T02:24:15.497591Z","shell.execute_reply.started":"2025-12-01T02:24:15.49212Z","shell.execute_reply":"2025-12-01T02:24:15.496805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barchartsdf\n\naccuracies = accuracy_of_estimates30df\nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(dual_column_list)[indices]\ncolumns = [\" & \".join(col) if isinstance(col, (list, np.ndarray)) else str(col) \n           for col in columns]\nprint (columns)\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#100 trees\naccuracy_of_estimatesdf = []\ndual_column_list=[]\nfor i in range(0,len(df.columns)-1,2):\n    if column in categorical_columns:\n        continue\n    accuracy_of_estimatesdf.append(DF_create_random_forest(df.columns[i], df.columns[i+1], 100))\n    dual_column_list.append([df.columns[i],df.columns[i+1]])\n\nprint (accuracy_of_estimatesdf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:24:46.377746Z","iopub.execute_input":"2025-12-01T02:24:46.378075Z","iopub.status.idle":"2025-12-01T02:49:53.477624Z","shell.execute_reply.started":"2025-12-01T02:24:46.378057Z","shell.execute_reply":"2025-12-01T02:49:53.476738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dictionary = {'100 Trees':accuracy_of_estimatesdf}\ndf_save= pd.DataFrame(save_dictionary)\ndf_save.to_pickle('100TreeDoubleFeatureAnalysis.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:26:47.196008Z","iopub.execute_input":"2025-12-01T03:26:47.19658Z","iopub.status.idle":"2025-12-01T03:26:47.203713Z","shell.execute_reply.started":"2025-12-01T03:26:47.196558Z","shell.execute_reply":"2025-12-01T03:26:47.202172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#barchartsdf\n\naccuracies = accuracy_of_estimatesdf\nindices = np.argsort(np.array(accuracies))[::-1]\naccuracies = np.array(accuracies)[indices]\ncolumns = np.array(dual_column_list)[indices]\ncolumns = [\" & \".join(col) if isinstance(col, (list, np.ndarray)) else str(col) \n           for col in columns]\nprint (columns)\nplt.xticks(rotation=90)\nprint (accuracies)\nplt.bar(columns[:10], accuracies[:10], width=.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T03:41:09.022826Z","iopub.execute_input":"2025-12-01T03:41:09.023142Z","iopub.status.idle":"2025-12-01T03:41:09.213877Z","shell.execute_reply.started":"2025-12-01T03:41:09.023127Z","shell.execute_reply":"2025-12-01T03:41:09.211997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#normalization\nx = df[\"miss_distance\"]\nxmin = x.min()\nx-=xmin\nxmax = x.max()\nx/=xmax\nprint (x, x.min(), x.max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:35:09.920503Z","iopub.execute_input":"2025-12-02T00:35:09.920879Z","iopub.status.idle":"2025-12-02T00:35:09.936047Z","shell.execute_reply.started":"2025-12-02T00:35:09.920851Z","shell.execute_reply":"2025-12-02T00:35:09.934725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#normalization\nx = df[\"miss_distance\"]\nxmin = x.min()\nx-=xmin\nindices = np.where(x==x.min())[0]\nindices2 = np.where(x!=x.min())[0]\nx2 = x[indices2]\nx[indices] = x2.min()\nx = np.log10(x)\nx-=x.min()\nxmax = x.max()\nx/=xmax\nprint (x, x.min(), x.max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T00:36:00.20721Z","iopub.execute_input":"2025-12-02T00:36:00.207598Z","iopub.status.idle":"2025-12-02T00:36:00.250548Z","shell.execute_reply.started":"2025-12-02T00:36:00.207563Z","shell.execute_reply":"2025-12-02T00:36:00.249581Z"}},"outputs":[],"execution_count":null}]}